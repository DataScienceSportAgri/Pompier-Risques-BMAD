# Story 2.4.5.3 : Modèle convolutif (neuronal) — troisième choix d’algorithme régression / classification

**Status:** Draft  
**Epic:** Epic 2 - Système de Simulation et Prédiction  
**Story Number:** 2.4.5.3

---

## Story

**As a** utilisateur,  
**I want** disposer d’un troisième choix d’algorithme « Modèle convolutif » en régression et en classification, entraînable, enregistrable et utilisable comme les modèles ML existants, prédisant exactement la même chose à partir des mêmes données,  
**so that** je peux comparer les performances d’un modèle neuronal (convolutionnel) avec Ridge/Huber et LogReg/XGBoost sur les mêmes objectifs.

---

## Acceptance Criteria

### A. Choix d’algorithme dans l’interface

1. Dans le **choix des algorithmes** (web_app.py, bloc ML 3×2 — Story 2.4.4), ajouter un **troisième choix** : **« Modèle convolutif »**.
2. **Régression** : l’utilisateur peut choisir Ridge, Huber ou **Modèle convolutif** ; le modèle convolutif prédit le **score ordinal** (même définition que Story 2.2.6 : `morts + 0.5 × blessés_graves`).
3. **Classification** : l’utilisateur peut choisir Logistic Regression, Gradient Boosting (XGBoost) ou **Modèle convolutif** ; le modèle convolutif prédit les **3 classes** (Normal / Pre-catastrophique / Catastrophique), comme les modèles de classification existants.

### B. Données d’entrée et de sortie

4. **Entrée** : **exactement les mêmes 90 features** que les modèles actuels (Story 2.3.1 — central sem_m1..m4, voisins_moy sem_m1 ; nomenclature identique).
5. **Sortie** : en régression, une **valeur continue** (score) ; en classification, une **classe parmi 3**. Les labels d’entraînement proviennent des mêmes pipelines (Story 2.2.6, 2.3.1) : pas de nouveau calcul de labels ni de features.

### C. Entraînement, sauvegarde et chargement

6. **Entraînement** : même workflow que les modèles ML existants (50 runs, extraction features/labels, entraînement). Le modèle convolutif est entraîné sur le même DataFrame (90 features + label score ou classe).
7. **Sauvegarde** : le modèle convolutif est **enregistré** comme les autres (métadonnées, numéro d’entraînement, paramètres). Format : joblib ou format framework neuronal (PyTorch/TensorFlow) selon implémentation ; stockage dans `data/models/regression/` ou `data/models/classification/` (ou sous-dossier dédié `convolutional/` si besoin).
8. **Chargement et prédiction** : depuis l’interface « Use a prediction model », l’utilisateur peut **charger** un modèle convolutif sauvegardé et l’utiliser pour **prédiction** comme Ridge/LogReg/XGBoost (même flux : 1 run affiché, prédictions par arrondissement et période).

### D. Métriques et cohérence

9. **Métriques** : en régression, MAE, RMSE, R² ; en classification, Accuracy, Precision, Recall, F1 (macro). Affichage dans l’interface après entraînement, comme pour les autres algorithmes.
10. **SHAP** : optionnel pour cette story ; si le code SHAP existant ne s’applique pas tel quel au modèle convolutif, documenter en Dev Notes (Phase 2 ou story dédiée).
11. **Tests manuels** : entraînement modèle convolutif (régression et classification), sauvegarde, chargement, prédictions cohérentes avec les colonnes Prédiction / Label réel ; pas de régression sur les autres algorithmes.

---

## Integration Verification

IV1: « Modèle convolutif » apparaît dans la liste des algorithmes (régression et classification) et peut être sélectionné.  
IV2: L’entraînement du modèle convolutif s’effectue sur les mêmes 90 features et labels que les autres modèles ; les métriques sont calculées et affichées.  
IV3: Le modèle convolutif sauvegardé peut être rechargé et utilisé pour prédiction (même format de sortie que Ridge/LogReg).  
IV4: Les prédictions (score ou 3 classes) sont exploitables dans les colonnes Prédiction / Label réel comme pour les modèles existants.

---

## Tasks / Subtasks

- [ ] Ajouter « Modèle convolutif » dans la liste des algorithmes (Régression et Classification) dans web_app.py
- [ ] Implémenter un modèle neuronal convolutif (ex. 1D CNN ou MLP) acceptant en entrée un vecteur de 90 features
- [ ] Branche régression : sortie continue (score) ; entraînement sur label `score`, métriques MAE, RMSE, R²
- [ ] Branche classification : sortie 3 classes ; entraînement sur label `classe`, métriques Accuracy, Precision, Recall, F1
- [ ] Intégrer l’entraînement du modèle convolutif dans le pipeline ML existant (MLService / MLTrainer ou module dédié)
- [ ] Implémenter sauvegarde du modèle (joblib ou format PyTorch/TF) avec métadonnées (numéro, params, feature_columns)
- [ ] Implémenter chargement et prédiction depuis l’interface (même flux que les autres modèles)
- [ ] Afficher les métriques après entraînement (régression ou classification selon mode)
- [ ] Tests manuels : entraînement, sauvegarde, chargement, prédiction ; non-régression autres algos

---

## Dev Notes

### Architecture Context

- **90 features** : Story 2.3.1 — même DataFrame, même nomenclature (central_sem_m1_*, …, voisins_moy_sem_m1_*).
- **Labels** : Story 2.2.6 — score (régression) ou classe 3 modalités (classification).
- **Bloc ML 3×2** : Story 2.4.1, 2.4.4 — ajout d’un troisième item dans le selectbox « Algorithmes ».

### Modèle « convolutif »

- **Interprétation** : réseau neuronal pouvant inclure des couches convolutives 1D (sur la séquence des 90 features, ex. 5 blocs de 18) ou un MLP ; l’objectif est d’avoir un **troisième algorithme neuronal** utilisant les mêmes entrées/sorties.
- **Framework** : PyTorch, TensorFlow/Keras ou scikit-learn (MLPClassifier/MLPRegressor) au choix ; préciser dans l’implémentation. Si PyTorch/TF : sauvegarde via `torch.save` / `model.save` et chargement dans un wrapper exposant `predict(X)` comme les autres modèles.
- **Préprocessing** : même normalisation ou pas que les autres modèles (à documenter ; si les autres n’utilisent pas de scaling, le modèle convolutif peut recevoir les features brutes ou un StandardScaler sauvegardé avec le modèle).

### Source Tree

```
src/ui/web_app.py                    # Ajout "Modèle convolutif" dans liste algos
src/services/
├── ml_service.py                    # Intégration entraînement/chargement/prédiction modèle convolutif
└── (ou) convolutional_model.py     # Module dédié : build, train, save, load, predict
data/models/
├── regression/                      # ridge_*.joblib, huber_*.joblib, convolutional_*.joblib (ou .pt)
└── classification/                  # logistic_*.joblib, xgboost_*.joblib, convolutional_*.joblib (ou .pt)
```

### Dépendances

- Story 2.3.1 (données ML 90 features), 2.2.6 (labels), 2.3.2 (pipeline entraînement), 2.4.4 (interface ML).
- Optionnel : PyTorch ou TensorFlow dans `requirements.txt` si modèle natif ; sinon MLP scikit-learn pour éviter nouvelle dépendance.

### SHAP

- Les modèles convolutifs ne sont en général pas compatibles directement avec le code SHAP des modèles linéaires/arbres. Cette story peut livrer sans SHAP pour le modèle convolutif ; documenter une évolution ultérieure (ex. KernelExplainer, ou story dédiée).

### Testing Standards

- Tests manuels : sélection « Modèle convolutif », entraînement, vérification métriques, sauvegarde, rechargement, prédictions affichées dans les colonnes Prédiction / Label réel.
- Non-régression : Ridge, Huber, LogReg, XGBoost inchangés.
- Optionnel : tests unitaires sur le module d’entraînement/chargement du modèle convolutif (format entrée/sortie, cohérence avec 90 features et label).

---

## Change Log

| Date       | Version | Description        | Author |
|------------|---------|--------------------|--------|
| 03 Feb 2026 | 1.0     | Création story     | PM     |
