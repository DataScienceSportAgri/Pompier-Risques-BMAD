# Story 2.3.3 : SHAP values pour interprétabilité

**Status:** Draft  
**Epic:** Epic 2 - Système de Simulation et Prédiction  
**Story Number:** 2.3.3

---

## Story

**As a** utilisateur décideur,  
**I want** voir SHAP values pour comprendre importance des 18 features,  
**so that** je peux faire confiance aux prédictions et comprendre les facteurs de risque.

---

## Acceptance Criteria

1. **Code SHAP** implémenté en MVP ; calcul pour chaque modèle (régression et classification) ; importance des 18 features (graphiques, summary).
2. **Bouton/checkbox** dans l'UI pour **lancer ou non** le calcul (peut être long).
3. Intégration workflow ML ; sauvegarde optionnelle. Visualisation dans Streamlit (Story 2.4.4).
4. Tests unitaires : calcul SHAP, format, visualisation.

---

## Integration Verification

IV1: Vérifier que SHAP peut être calculé pour tous modèles (compatibilité)  
IV2: Vérifier que les SHAP values sont cohérentes (importance features logique)  
IV3: Vérifier que la visualisation SHAP fonctionne dans Streamlit

---

## Tasks / Subtasks

- [ ] Implémenter calcul SHAP values pour modèles régression (RF, Ridge)
- [ ] Implémenter calcul SHAP values pour modèles classification (LogReg, XGBoost)
- [ ] Implémenter importance des 18 features (graphiques, summary)
- [ ] Implémenter intégration workflow ML (après entraînement)
- [ ] Implémenter sauvegarde optionnelle SHAP values
- [ ] Implémenter checkbox/bouton dans UI (Story 2.4.4) pour lancer calcul
- [ ] Implémenter visualisation SHAP dans Streamlit
- [ ] Tests : calcul SHAP, format, visualisation

---

## Dev Notes

### Architecture Context

- **SHAP values** : Interprétabilité modèles ML (FR8, FR28)
- **Code présent en MVP** : Implémentation complète
- **Calcul** : Pour chaque modèle (régression et classification)
- **Importance features** : 18 features (graphiques, summary)
- **UI** : Checkbox/bouton pour lancer ou non (peut être long)
- **Visualisation** : Dans Streamlit (Story 2.4.4)

### Source Tree

```
src/services/
└── ml_service.py            # Calcul SHAP values

src/adapters/ui/
└── streamlit_app.py         # Visualisation SHAP (Story 2.4.4)

data/models/
└── shap_values/             # Sauvegarde optionnelle SHAP
```

### Dependencies

- MLService : Story 2.3.2 (modèles entraînés)
- UI Streamlit : Story 2.4.4 (visualisation)
- SHAP library : Dépendance externe

### Calcul SHAP

```python
import shap

# Pour chaque modèle
explainer = shap.TreeExplainer(model)  # ou LinearExplainer, etc.
shap_values = explainer.shap_values(X_test)

# Importance features
shap.summary_plot(shap_values, X_test, feature_names=feature_names)
```

### Testing Standards

- Tests unitaires : Calcul SHAP, format, visualisation
- Tests de validation : SHAP values cohérentes (importance features logique)
- Framework : pytest
- Emplacement : `tests/services/test_ml_service.py`

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 28 Jan 2026 | 1.0 | Création story | PM |
