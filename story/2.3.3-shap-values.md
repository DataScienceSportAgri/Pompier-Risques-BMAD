# Story 2.3.3 : SHAP values pour interprétabilité

**Status:** Draft  
**Epic:** Epic 2 - Système de Simulation et Prédiction  
**Story Number:** 2.3.3

---

## Story

**As a** utilisateur décideur,  
**I want** voir SHAP values pour comprendre importance des **90 features** (nomenclature claire : central sem_m1..m4, voisins_moy sem_m1),  
**so that** je peux faire confiance aux prédictions et comprendre les facteurs de risque.

---

## Acceptance Criteria

1. **Code SHAP** implémenté en MVP ; calcul pour chaque modèle (régression et classification) ; importance des **90 features** (noms clairs : central_sem_m1_*, central_sem_m2_*, ..., voisins_moy_sem_m1_* ; sem_m1 = dernière semaine / week -1, voisins_moy = moyenne des 4 adjacents).
2. **Bouton/checkbox** dans l'UI pour **lancer ou non** le calcul (peut être long).
3. Intégration workflow ML ; sauvegarde optionnelle. Visualisation dans Streamlit (Story 2.4.4).
4. Tests unitaires : calcul SHAP, format, visualisation.

---

## Integration Verification

IV1: Vérifier que SHAP peut être calculé pour tous modèles (compatibilité)  
IV2: Vérifier que les SHAP values sont cohérentes (importance features logique)  
IV3: Vérifier que la visualisation SHAP fonctionne dans Streamlit

---

## Tasks / Subtasks

- [x] Implémenter calcul SHAP values pour modèles régression (Huber, Ridge)
- [x] Implémenter calcul SHAP values pour modèles classification (LogReg, XGBoost)
- [x] Implémenter importance des 90 features (noms clairs : central_sem_m*, voisins_moy_sem_m1 ; compute_shap_values)
- [ ] Implémenter intégration workflow ML (après entraînement)
- [x] Implémenter sauvegarde optionnelle SHAP values (save_shap_values)
- [ ] Implémenter checkbox/bouton dans UI (Story 2.4.4) pour lancer calcul
- [ ] Implémenter visualisation SHAP dans Streamlit
- [x] Tests : calcul SHAP, format (test_ml_service.TestSHAP)

---

## Dev Notes

### Architecture Context

- **SHAP values** : Interprétabilité modèles ML (FR8, FR28)
- **Code présent en MVP** : compute_shap_values, save_shap_values dans ml_service.py
- **Calcul** : Pour chaque modèle (régression et classification) ; LinearExplainer (Huber, Ridge, LogReg), TreeExplainer (XGBoost)
- **Importance features** : 90 features avec nomenclature commune (central_sem_m1_*, central_sem_m2_*, ..., voisins_moy_sem_m1_* ; sem_m1 = week -1, voisins_moy = moyenne des 4 adjacents)
- **UI** : Checkbox/bouton pour lancer ou non (Story 2.4.4)
- **Visualisation** : Dans Streamlit (Story 2.4.4)

### Source Tree

```
src/services/
└── ml_service.py            # Calcul SHAP values

src/adapters/ui/
└── streamlit_app.py         # Visualisation SHAP (Story 2.4.4)

data/models/
└── shap_values/             # Sauvegarde optionnelle SHAP
```

### Dependencies

- MLService : Story 2.3.2 (modèles entraînés)
- UI Streamlit : Story 2.4.4 (visualisation)
- SHAP library : Dépendance externe

### Calcul SHAP

```python
import shap

# Pour chaque modèle
explainer = shap.TreeExplainer(model)  # ou LinearExplainer, etc.
shap_values = explainer.shap_values(X_test)

# Importance features
shap.summary_plot(shap_values, X_test, feature_names=feature_names)
```

### Testing Standards

- Tests unitaires : Calcul SHAP, format, visualisation
- Tests de validation : SHAP values cohérentes (importance features logique)
- Framework : pytest
- Emplacement : `tests/services/test_ml_service.py` (classe TestSHAP)

---

## Dev Agent Record

### Agent Model Used
(Cursor / Agent dev)

### Completion Notes
- ✅ compute_shap_values(model, X, feature_names, model_type="linear"|"tree", max_samples) dans ml_service.py
- ✅ Nomenclature 90 features : central_sem_m1_*, central_sem_m2_*, ..., voisins_moy_sem_m1_* (sem_m1 = week -1, voisins_moy = moyenne 4 adjacents)
- ✅ LinearExplainer pour Huber, Ridge, LogReg ; TreeExplainer pour XGBoost
- ✅ save_shap_values(shap_result, path, algo_name) pour sauvegarde optionnelle joblib
- ✅ Tests : TestSHAP (compute_shap_values linear, save_shap_values)
- ✅ Passage à 90 features (story 2.3.1/2.3.2) et nomenclature commune

### File List
**Fichiers modifiés :**
- `src/services/ml_service.py` - 90 features (voisins_moy), nomenclature sem_m1..m4, compute_shap_values, save_shap_values
- `src/services/__init__.py` - Export compute_shap_values, save_shap_values
- `tests/services/test_ml_service.py` - 90 features, TestSHAP
- `story/2.3.1-preparation-donnees-ml.md` - 90 features, nomenclature
- `story/2.3.2-entrainement-modeles-ml.md` - 90 features
- `story/2.3.3-shap-values.md` - 90 features, nomenclature, Dev Agent Record

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 28 Jan 2026 | 1.0 | Création story | PM |
| 29 Jan 2026 | 1.1 | 90 features, nomenclature sem_m1..m4/voisins_moy ; compute_shap_values, save_shap_values (ml_service) | Dev |
