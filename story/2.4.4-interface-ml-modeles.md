# Story 2.4.4 : Interface Streamlit — ML et modèles sauvegardés

**Status:** Draft  
**Epic:** Epic 2 - Système de Simulation et Prédiction  
**Story Number:** 2.4.4

---

## Story

**As a** utilisateur,  
**I want** entraîner modèles ML et charger modèles sauvegardés pour prédiction,  
**so that** je peux utiliser le système pour prédictions réelles.

---

## Acceptance Criteria

1. Bloc ML 3×2 (layout 2.4.1) **connecté** aux modules ML : Train a model / Use a prediction model, Régression / Classification, 2 algos (RF, Ridge, LogReg, XGBoost).
2. **Bouton/checkbox** pour **calcul SHAP** (lancer ou non) ; code SHAP présent en MVP. Métadonnées modèles (nom, n° entraînement, jours, accuracy).
3. Entraînement depuis interface ; métriques (MAE, RMSE, R² ou Accuracy, Precision, Recall, F1) ; SHAP si coché.
4. **Entraînement** : **1 run** affiché à l'écran (0.33 s/jour) + **49 runs** en calcul seul pour ML. **Prédiction** : **1 run** affiché uniquement, pas de runs en calcul seul.
5. Tests manuels : entraînement, chargement, prédiction, visualisations.

---

## Integration Verification

IV1: Vérifier que l'entraînement depuis interface fonctionne (pas d'erreurs, modèles sauvegardés)  
IV2: Vérifier que le chargement modèles fonctionne (liste fichiers, métadonnées affichées)  
IV3: Vérifier que les prédictions avec modèle chargé fonctionnent (format, valeurs cohérentes)

---

## Tasks / Subtasks

- [x] Connecter bloc ML 3×2 (Story 2.4.1) aux modules ML
- [x] Implémenter radio "Train a model" / "Use a prediction model"
- [x] Implémenter radio "Régression" / "Classification"
- [x] Implémenter sélection 2 algorithmes (RF, Ridge, LogReg, XGBoost)
- [x] Implémenter sélection fichier modèle (si "Use prediction")
- [x] Implémenter saisie nom modèle (avec génération automatique)
- [x] Implémenter checkbox/bouton calcul SHAP
- [x] Implémenter entraînement depuis interface (appel MLService)
- [x] Implémenter affichage métriques (MAE, RMSE, R² ou Accuracy, Precision, Recall, F1)
- [x] Implémenter affichage métadonnées modèles (nom, n° entraînement, jours, accuracy)
- [x] Implémenter chargement modèles sauvegardés (liste fichiers)
- [x] Implémenter mode prédiction (1 run affiché uniquement)
- [x] Implémenter visualisation SHAP (si calculé)
- [ ] Tests manuels : entraînement, chargement, prédiction, visualisations

---

## Dev Notes

### Architecture Context

- **Bloc ML 3×2** : Tableau logique 3 colonnes × 2 lignes (FR19, Story 2.4.1)
- **Train a model** : Entraînement après 50 runs terminés (FR23)
- **Use a prediction model** : Chargement modèle sauvegardé pour prédiction (FR22)
- **Algorithmes** : RF, Ridge (régression), LogReg, XGBoost (classification) (FR19)
- **SHAP** : Code présent en MVP, checkbox pour lancer ou non (FR8, FR28)
- **Métriques** : MAE, RMSE, R² (régression), Accuracy, Precision, Recall, F1 (classification) (NFR9)
- **Entraînement** : 1 run affiché + 49 runs en calcul seul (FR23)
- **Prédiction** : 1 run affiché uniquement (FR22)

### Source Tree

```
src/adapters/ui/
└── streamlit_app.py         # Application Streamlit (bloc ML 3×2)

src/services/
└── ml_service.py            # Service ML (Story 2.3.2)

data/models/
├── regression/
│   ├── random_forest_001_params.joblib
│   └── ridge_001_params.joblib
└── classification/
    ├── logistic_regression_001_params.joblib
    └── xgboost_001_params.joblib
```

### Dependencies

- Layout Streamlit : Story 2.4.1 (bloc ML 3×2)
- MLService : Story 2.3.2 (entraînement modèles)
- SHAP : Story 2.3.3 (calcul SHAP values)
- Features/Labels : Story 2.2.5, 2.2.6 (données ML)

### Bloc ML 3×2 (FR19)

**Ligne 1 :**
- Colonne 1 : Radio "Train a model" / "Use a prediction model"
- Colonne 2 : Radio "Régression" / "Classification"
- Colonne 3 : Si "Use prediction" : sélection fichier modèle

**Ligne 2 :**
- Si "Train" : Sélection 2 algorithmes + saisie nom modèle (génération automatique)
- Si "Use prediction" : Lié à sélection modèle ligne 1

### Testing Standards

- Tests manuels : Entraînement, chargement, prédiction, visualisations
- Tests d'intégration : Connexion bloc ML → MLService
- Framework : Tests manuels (pas d'automatisation pour UI Streamlit en MVP)
- Emplacement : Tests manuels documentés

---

## Dev Agent Record

### File List
- `src/services/ml_data_extractor.py` (nouveau) — Extraction features/labels depuis SimulationState, logique 4*4 sem min
- `src/services/ml_service.py` (modifié) — workflow_extract_then_prepare, calibrate_labels_classification
- `src/services/label_calculator.py` (modifié) — Constantes calibration 85/10/5
- `src/ui/web_app.py` (modifié) — Connexion ML (entraînement, prédiction, métriques, SHAP)
- `scripts/run_ml_training.py` (nouveau) — Script CLI pour entraînement complet

### Completion Notes
- Logique comptage : 4 mois min (16 sem), +2 mois par incrément jusqu'à 100 mois (400 sem)
- Calibration classification : percentiles score → ~85% Normal, ~10% Pre-cata, ~5% Cata
- Entraînement : 50 runs headless + extraction + train ; prédiction : 1 run state + modèle chargé

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 28 Jan 2026 | 1.0 | Création story | PM |
| 02 Feb 2026 | 1.1 | Implémentation Story 2.4.4 | Dev |
