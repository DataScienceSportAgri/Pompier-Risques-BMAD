# Review Architecture Document - Point de Vue Architect Manager

**Date:** 28 Janvier 2026  
**Reviewer:** Architect Manager (perspective critique)  
**Document reviewÃ©:** `docs/architecture.md` v1

---

## ğŸŸ¢ Points Forts

### 1. Structure et ComplÃ©tude
- âœ… **Documentation complÃ¨te:** Tous les aspects couverts (layers, patterns, data flow)
- âœ… **TraÃ§abilitÃ©:** RÃ©fÃ©rences claires au PRD et dÃ©cisions techniques
- âœ… **Diagrammes:** Mermaid utile pour visualisation
- âœ… **Exemples de code:** Concrets et actionnables

### 2. DÃ©cisions Techniques
- âœ… **Architecture hexagonale:** Choix appropriÃ© pour extensibilitÃ© (plugins, remplacement donnÃ©es)
- âœ… **NumPy pour calculs:** Bon choix performance
- âœ… **Dependency Injection:** Facilite tests
- âœ… **Patterns cohÃ©rents:** Strategy, Factory bien utilisÃ©s

### 3. Pragmatisme MVP
- âœ… **Direct pickle:** YAGNI respectÃ© (pas de sur-abstraction)
- âœ… **Monolithique modulaire:** AppropriÃ© pour MVP
- âœ… **Streamlit:** Choix pragmatique pour UI rapide

---

## ğŸ”´ Points Faibles et Risques

### 1. **CRITIQUE: SimulationState comme God Object**

**ProblÃ¨me:**
```python
class SimulationState:
    # 10+ responsabilitÃ©s diffÃ©rentes
    - vectors
    - regimes
    - events_graves
    - events_positifs
    - morts
    - blesses_graves
    - features
    - labels
    # ...
```

**Risques:**
- âŒ **Violation SRP:** SimulationState fait trop de choses
- âŒ **Couplage fort:** Tous les composants dÃ©pendent de SimulationState
- âŒ **TestabilitÃ© rÃ©duite:** Difficile de tester composants isolÃ©ment
- âŒ **Ã‰volutivitÃ©:** Ajout nouvelles donnÃ©es = modification SimulationState partout

**Recommandation:**
```python
# Mieux: AgrÃ©gation de domaines
class SimulationState:
    def __init__(self):
        self.vectors_state = VectorsState()
        self.events_state = EventsState()
        self.casualties_state = CasualtiesState()
        self.ml_state = MLState()
```

**Impact:** ğŸ”´ **HAUT** - Risque de dette technique importante

---

### 2. **CRITIQUE: Architecture Hexagonale Overkill pour MVP?**

**Question:** Est-ce vraiment nÃ©cessaire pour un MVP local, sans API, sans BDD?

**Risques:**
- âš ï¸ **ComplexitÃ© initiale:** Plus de code Ã  Ã©crire (interfaces, adapters)
- âš ï¸ **Temps de dÃ©veloppement:** Plus long pour livrer MVP
- âš ï¸ **Over-engineering:** YAGNI violÃ© si Phase 2 jamais atteinte

**Contre-argument valide:**
- âœ… Requirement PRD explicite: "plugins/modulateurs sans toucher le cÅ“ur"
- âœ… Phase 2: Remplacement donnÃ©es gÃ©nÃ©rÃ©es â†’ vraies donnÃ©es BSPP

**Verdict:** âœ… **JustifiÃ©** mais nÃ©cessite discipline pour ne pas sur-abstraire

---

### 3. **CRITIQUE: Plugin Registry - OÃ¹ est l'usage rÃ©el?**

**ProblÃ¨me:**
- Document dÃ©crit le pattern mais **aucun cas d'usage concret** dans le PRD
- Pas d'exemple de plugin rÃ©el nÃ©cessaire
- Risque de code mort (pattern jamais utilisÃ©)

**Questions Ã  poser:**
- Qui va crÃ©er des plugins? Quand? Pourquoi?
- Est-ce vraiment nÃ©cessaire en MVP?
- Phase 2 suffit?

**Recommandation:** 
- âš ï¸ **Phase 2 uniquement** sauf si requirement explicite MVP
- Ou documenter **cas d'usage concret** justifiant MVP

---

### 4. **CRITIQUE: Gestion Multi-Runs - ComplexitÃ© sous-estimÃ©e**

**ProblÃ¨me:**
```python
# Document mentionne "sauvegarde incrÃ©mentale" mais...
# - Comment gÃ©rer les erreurs pendant parallÃ©lisation?
# - Que faire si un run Ã©choue?
# - Comment reprendre aprÃ¨s crash?
# - Gestion mÃ©moire: 49 runs Ã— 200 MB = 10 GB (acceptable mais...)
```

**Risques:**
- âŒ **Pas de stratÃ©gie d'erreur:** Un run Ã©choue â†’ tout Ã©choue?
- âŒ **Pas de retry:** Run silencieux Ã©choue â†’ perdu?
- âŒ **Pas de monitoring:** Comment savoir si runs silencieux progressent?
- âŒ **Ã‰tat partiel:** Run interrompu â†’ donnÃ©es corrompues?

**Manques:**
- StratÃ©gie de retry
- Gestion d'erreurs robuste
- Monitoring/observabilitÃ©
- Validation Ã©tat aprÃ¨s crash

**Impact:** ğŸ”´ **HAUT** - Risque de perte de donnÃ©es, frustration utilisateur

---

### 5. **CRITIQUE: Streamlit + Simulation Temps RÃ©el - Blocage UI**

**ProblÃ¨me:**
```python
# Streamlit bloque pendant calculs
for day in range(365):
    service.run_day(day)  # Bloque UI pendant 0.33s Ã— 365 = 2 minutes
    update_ui()  # Jamais appelÃ© pendant le calcul
```

**Risques:**
- âŒ **UI non rÃ©active:** Streamlit bloque pendant calculs
- âŒ **Pas de vrai "temps rÃ©el":** UI se met Ã  jour aprÃ¨s, pas pendant
- âŒ **Stop difficile:** Comment arrÃªter si UI bloquÃ©e?

**Solutions possibles:**
- Threading (mais GIL limite)
- `st.rerun()` pÃ©riodique (hack)
- Async/await (complexe avec Streamlit)

**Manque dans document:** âš ï¸ **Pas de solution proposÃ©e**

**Impact:** ğŸŸ¡ **MOYEN** - UX dÃ©gradÃ©e mais acceptable pour MVP

---

### 6. **CRITIQUE: Pas de Gestion d'Erreurs**

**ProblÃ¨me:**
- Aucune section sur gestion d'erreurs
- Pas de stratÃ©gie de retry
- Pas de logging structurÃ©
- Pas de validation des donnÃ©es

**Exemples manquants:**
```python
# Que se passe-t-il si:
- Fichier pickle corrompu?
- DonnÃ©es prÃ©-calculÃ©es manquantes?
- ModÃ¨le ML invalide?
- Erreur calcul Golden Hour?
- Run interrompu brutalement?
```

**Recommandation:**
- Section "Error Handling Strategy"
- Logging structurÃ© (structlog ou logging standard)
- Validation donnÃ©es (pydantic?)
- Retry pour I/O

**Impact:** ğŸ”´ **HAUT** - SystÃ¨me fragile, difficile Ã  dÃ©boguer

---

### 7. **CRITIQUE: Performance - Pas de Benchmarks**

**ProblÃ¨me:**
- Objectif: â‰¤ 0.33s/jour
- Mais **aucune validation** que c'est rÃ©aliste
- Pas de profiling strategy
- Pas de mÃ©triques de performance

**Questions:**
- Comment mesurer si 0.33s atteint?
- Que faire si dÃ©passÃ©?
- Quels composants sont les bottlenecks?

**Recommandation:**
- Section "Performance Monitoring"
- Profiling strategy (cProfile, line_profiler)
- MÃ©triques Ã  collecter
- Plan d'action si objectif non atteint

**Impact:** ğŸŸ¡ **MOYEN** - Risque de non-respect NFR

---

### 8. **CRITIQUE: Tests - Couverture Vague**

**ProblÃ¨me:**
```python
# Document dit: "Couverture cible: 70%+ pour composants critiques"
# Mais:
- Quels sont les "composants critiques"?
- Comment mesurer?
- Quand tester? (TDD? AprÃ¨s?)
- Tests d'intÃ©gration: combien?
```

**Manques:**
- StratÃ©gie de test claire
- DÃ©finition "composants critiques"
- Outils (pytest-cov)
- CI/CD (quand tests lancÃ©s?)

**Impact:** ğŸŸ¡ **MOYEN** - QualitÃ© code incertaine

---

### 9. **CRITIQUE: Data Flow - Ordre d'ExÃ©cution Flou**

**ProblÃ¨me:**
```python
# Document montre sÃ©quence mais...
# - Ordre exact des opÃ©rations?
# - DÃ©pendances entre Ã©tapes?
# - Que faire si Ã©tape Ã©choue?
# - Rollback possible?
```

**Exemple concret:**
```python
# Story 2.2.1 â†’ 2.2.9 â†’ 2.2.10 â†’ 2.2.3
# Mais dans le code, ordre rÃ©el?
```

**Manque:** Diagramme de dÃ©pendances explicite

**Impact:** ğŸŸ¡ **MOYEN** - Risque d'implÃ©mentation incorrecte

---

### 10. **CRITIQUE: Configuration - Pas de Validation**

**ProblÃ¨me:**
```yaml
# config.yaml
scenarios:
  pessimiste:
    facteur_intensite: 1.3  # Que faire si nÃ©gatif? > 10?
```

**Risques:**
- âŒ Pas de validation config au dÃ©marrage
- âŒ Erreurs dÃ©couvertes en runtime
- âŒ Pas de schÃ©ma config (JSON Schema?)

**Recommandation:**
- Validation config avec pydantic
- SchÃ©ma config documentÃ©
- Valeurs par dÃ©faut claires

**Impact:** ğŸŸ¡ **MOYEN** - Erreurs runtime Ã©vitables

---

## ğŸŸ¡ Points d'Attention

### 11. **Dependency Injection - Pas de Container**

**Question:**
- Comment crÃ©er les objets? Manuellement partout?
- Pas de DI container (injector, dependency-injector)?

**Risque:**
- Code rÃ©pÃ©titif pour crÃ©ation objets
- Difficile Ã  maintenir si beaucoup de dÃ©pendances

**Recommandation:**
- DI container simple (ou manuel si < 10 classes)
- Factory pour crÃ©ation objets complexes

---

### 12. **NumPy Arrays - Conversion Overhead**

**Question:**
- Tuples â†’ NumPy arrays: conversion Ã  chaque fois?
- Ou garder arrays dÃ¨s le dÃ©but?

**Risque:**
- Overhead conversion si fait souvent
- CohÃ©rence: tuples vs arrays?

**Recommandation:**
- DÃ©cision claire: tuples partout ou arrays partout?
- Documenter choix

---

### 13. **Golden Hour - ComplexitÃ© Sous-estimÃ©e**

**Question:**
- Calcul congestion: comment modÃ©lisÃ©?
- Stress pompiers: comment suivi?
- Performance: 100 microzones Ã— calculs = ?

**Risque:**
- ComplexitÃ© algorithmique non documentÃ©e
- Performance bottleneck potentiel

**Recommandation:**
- Algorithme dÃ©taillÃ© dans `docs/formules.md`
- Profiling prÃ©vu

---

### 14. **ML Service - Pas de DÃ©tails**

**Question:**
- Comment prÃ©pare-t-on les 90 features?
- FenÃªtres glissantes: implÃ©mentation?
- Validation donnÃ©es ML?

**Manque:**
- DÃ©tails prÃ©paration donnÃ©es ML
- Pipeline ML complet

---

### 15. **ExtensibilitÃ© Phase 2 - Pas de Migration Path**

**Question:**
- Comment migrer pickle â†’ BDD?
- Breaking changes?
- CompatibilitÃ© donnÃ©es?

**Manque:**
- StratÃ©gie migration
- Plan de transition

---

## âœ… Recommandations Prioritaires

### PrioritÃ© 1 (Critique - Ã€ faire maintenant)

1. **Refactor SimulationState:**
   - DÃ©couper en domaines (VectorsState, EventsState, etc.)
   - RÃ©duire couplage

2. **Gestion d'erreurs:**
   - Section complÃ¨te "Error Handling Strategy"
   - Logging structurÃ©
   - Retry strategy

3. **Gestion multi-runs robuste:**
   - StratÃ©gie erreurs
   - Retry automatique
   - Monitoring

4. **Streamlit + temps rÃ©el:**
   - Solution proposÃ©e (threading? async?)
   - Ou accepter limitation et documenter

### PrioritÃ© 2 (Important - Ã€ planifier)

5. **Performance monitoring:**
   - Profiling strategy
   - MÃ©triques Ã  collecter
   - Benchmarks

6. **Tests:**
   - StratÃ©gie claire
   - DÃ©finition "composants critiques"
   - CI/CD

7. **Configuration:**
   - Validation (pydantic)
   - SchÃ©ma config

### PrioritÃ© 3 (AmÃ©lioration - Phase 2)

8. **Plugin Registry:**
   - Cas d'usage concret ou Phase 2

9. **Migration path:**
   - StratÃ©gie pickle â†’ BDD

10. **ObservabilitÃ©:**
    - Monitoring avancÃ©
    - MÃ©triques business

---

## ğŸ“Š Score Global

| CritÃ¨re | Score | Commentaire |
|---------|-------|-------------|
| **ComplÃ©tude** | 8/10 | Bien couvert mais manques critiques |
| **CohÃ©rence** | 7/10 | Quelques incohÃ©rences (SimulationState) |
| **Pragmatisme** | 6/10 | Hexagonale peut-Ãªtre overkill MVP |
| **TestabilitÃ©** | 7/10 | DI bon mais SimulationState couplÃ© |
| **Performance** | 5/10 | Pas de stratÃ©gie monitoring |
| **Robustesse** | 4/10 | âš ï¸ **CRITIQUE:** Pas de gestion erreurs |
| **MaintenabilitÃ©** | 7/10 | Structure bonne mais SimulationState problÃ©matique |
| **ExtensibilitÃ©** | 8/10 | Hexagonale + plugins bien pensÃ©s |

**Score moyen: 6.5/10**

**Verdict:** 
- âœ… **Bon dÃ©part** mais **manques critiques** Ã  adresser
- âš ï¸ **Risque de dette technique** si SimulationState non refactorÃ©
- âš ï¸ **Risque de frustration** si gestion erreurs absente
- âœ… **Architecture solide** mais besoin de **robustesse opÃ©rationnelle**

---

## ğŸ¯ Actions ImmÃ©diates RecommandÃ©es

1. **Refactor SimulationState** (1-2 jours)
2. **Ajouter section Error Handling** (0.5 jour)
3. **DÃ©tailler gestion multi-runs** (1 jour)
4. **Solution Streamlit temps rÃ©el** (0.5 jour)

**Total: ~3-4 jours de travail architecture avant implÃ©mentation**

---

**Fin du review**
